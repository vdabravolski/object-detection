{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to satisfy following requirements:\n",
    "# 1. pip instsall -r requirements.txt\n",
    "# 2. pip install \"git+https://github.com/philferriere/cocoapi.git#egg=pycocotools&subdirectory=PythonAPI\" \n",
    "# to address this issue: https://github.com/matterport/Mask_RCNN/issues/6\n",
    "# also, you can specify this in reuirements.txt like this: https://stackoverflow.com/questions/16584552/how-to-state-in-requirements-txt-a-direct-github-source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting objects using Mask RCNN model\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Setup](#Setup)\n",
    "3. [Host pretrained model](#Host-pretrained-model)\n",
    "4. [Train model](#Train-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before preparing the data, there are some initial steps required for setup. To train the image classification algorithm on Amazon SageMaker, we need to setup and authenticate the use of AWS services. To begin with, we need an AWS account role with SageMaker access. Here we will use the execution role the current notebook instance was given when it was created.  This role has necessary permissions, including access to your data in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::480604769687:role/service-role/AmazonSageMaker-ExecutionRole-20190530T172586\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to identify the S3 bucket that you want to use for providing training and validation datasets. It will be used to store the tranied model artifacts as well. In this notebook, we use a default bucket for use with SageMaker in your account. Alternatively, you could use whatever bucket you would like. We use an object prefix to help organize the bucket content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sess.default_bucket() # or use your own custom bucket name\n",
    "prefix = 'DEMO-RCNN-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instal Dependencies\n",
    "See details here: https://github.com/matterport/Mask_RCNN\n",
    "\n",
    "\n",
    "\n",
    "1. Clone this repository\n",
    "\n",
    "2. Install dependencies\n",
    "pip3 install -r requirements.txt\n",
    "\n",
    "3. Run setup from the repository root directory\n",
    "python3 setup.py install\n",
    "\n",
    "4. Download pre-trained COCO weights (mask_rcnn_coco.h5) from the releases page.\n",
    "\n",
    "5. (Optional) To train or test on MS COCO install pycocotools from one of these repos. They are forks of the original pycocotools with fixes for Python3 and Windows (the official repo doesn't seem to be active anymore).\n",
    "Linux: https://github.com/waleedka/coco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[04m\u001b[31;01m!\u001b[39;49;00m git clone https://github.com/matterport/Mask_RCNN\n",
      "\u001b[04m\u001b[31;01m!\u001b[39;49;00m cd Mask_RCNN\n",
      "\u001b[04m\u001b[31;01m!\u001b[39;49;00m python setup.py install\n"
     ]
    }
   ],
   "source": [
    "! pygmentize code/setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference of of pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
